{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas, Bio.Entrez, and BioMed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "Entrez.email = \"araz.rawshani@gu.se\"  # Replace with your actual email address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for AI papers by invited reserachers to Sanofi's meeting\n",
    "\n",
    "### Define search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Parameters\n",
    "\n",
    "# List of authors to search for\n",
    "authors = [\n",
    "    \"Grenne B\",\n",
    "    \"van den Boogaard M\",\n",
    "    \"Kylmala Minna\",\n",
    "    \"Vejlstrup Niels\",\n",
    "    \"Oerlemans Marish\",\n",
    "    \"Rawshani A\",\n",
    "]\n",
    "\n",
    "# List of keywords to search for in the title or abstract\n",
    "keywords = [\n",
    "    \"deep learning\",\n",
    "    \"neural network*\",\n",
    "    \"machine learning\",\n",
    "    \"lstm\"\n",
    "]\n",
    "\n",
    "# Combine authors and keywords into a single search query\n",
    "author_query = \" OR \".join([f'\"{author}\"[Author]' for author in authors])\n",
    "keyword_query = \" OR \".join([f'\"{keyword}\"' for keyword in keywords])\n",
    "search_query = f\"({author_query}) AND ({keyword_query})\"\n",
    "\n",
    "# Display the search query\n",
    "print(\"Search Query:\", search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search PubMed\n",
    "handle = Entrez.esearch(db=\"pubmed\", term=search_query, retmax=200)\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "# Fetch details of the articles\n",
    "id_list = record[\"IdList\"]\n",
    "handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(id_list), rettype=\"medline\", retmode=\"text\")\n",
    "records = handle.read()\n",
    "handle.close()\n",
    "\n",
    "# Parse the fetched records\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "\n",
    "medline_records = Medline.parse(records.splitlines())\n",
    "articles = []\n",
    "\n",
    "for record in medline_records:\n",
    "    article = {\n",
    "        \"PMID\": record.get(\"PMID\", \"\"),\n",
    "        \"Title\": record.get(\"TI\", \"\"),\n",
    "        \"Abstract\": record.get(\"AB\", \"\"),\n",
    "        \"Authors\": record.get(\"AU\", []),\n",
    "        \"Journal\": record.get(\"JT\", \"\"),\n",
    "        \"Publication Date\": record.get(\"DP\", \"\")\n",
    "    }\n",
    "    articles.append(article)\n",
    "\n",
    "# Convert the list of articles to a pandas DataFrame\n",
    "df = pd.DataFrame(articles)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of authors to search for\n",
    "authors = [\n",
    "    \"Grenne\",\n",
    "    \"Boogaard\",\n",
    "    \"Kylmala\",\n",
    "    \"Vejlstrup\",\n",
    "    \"Oerlemans\",\n",
    "    \"Rawshani\",\n",
    "]\n",
    "\n",
    "# Function to identify authors in the row\n",
    "def identify_authors(row, authors):\n",
    "    if row.get('Authors'):\n",
    "        identified_authors = [author for author in authors if any(author in au for au in row['Authors'])]\n",
    "        return \", \".join(identified_authors)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Create the \"AuthorIdentified\" column\n",
    "df[\"AuthorIdentified\"] = df.apply(identify_authors, axis=1, authors=authors)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Count the occurrences of each author in the IdentifiedAuthor column\n",
    "author_counts = df[\"AuthorIdentified\"].value_counts().reset_index()\n",
    "author_counts.columns = [\"Author\", \"Count\"]\n",
    "\n",
    "# Create a bar chart\n",
    "fig = px.bar(author_counts, x=\"Author\", y=\"Count\", title=\"Counts for Each Identified Author\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display each paper's title and abstract\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Title: {row['Title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "df.to_csv(\"pubmed_search_results_sanofi_team.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pubmed_search_results_sanofi_team_manually_labelled.csv\n",
    "df2 = pd.read_excel(\"pubmed_search_results_sanofi_team_manually_labelled.xlsx\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Count the occurrences of each modality and topic\n",
    "modality_counts = df2.groupby(['Modality', 'Topic']).size().reset_index(name='Count')\n",
    "\n",
    "# Create a bar chart\n",
    "fig = px.bar(modality_counts, x='Modality', y='Count', color='Topic', title='Counts for Each Modality Colored by Topic')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total reserach on deep learning in HCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search parameters\n",
    "keywords = [\"deep learning\", \"neural network*\", \"machine learning\", \"transformer*\", \"gradient boost*\", \"artificial intelligence\"]\n",
    "conditions = [\"hypertrophic cardiomyopath*\", \"hypertrophic obstructive cardiomyopath*\"]\n",
    "\n",
    "# Function to search PubMed\n",
    "def search_pubmed(keywords, conditions):\n",
    "    Entrez.email = \"your.email@example.com\"  # Always tell NCBI who you are\n",
    "    query = f'({\" OR \".join(keywords)}) AND ({\" OR \".join(conditions)})'\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=1000)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"]\n",
    "\n",
    "# Function to fetch details of articles\n",
    "def fetch_details(id_list):\n",
    "    ids = \",\".join(id_list)\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(handle)\n",
    "    return list(records)\n",
    "\n",
    "# Search PubMed and fetch details\n",
    "id_list = search_pubmed(keywords, conditions)\n",
    "articles = fetch_details(id_list)\n",
    "\n",
    "# Save data to pandas DataFrame\n",
    "df_all = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which studies are clearly HCM studies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with an empty string\n",
    "df_all[\"TI\"] = df_all[\"TI\"].fillna(\"\")\n",
    "df_all[\"AB\"] = df_all[\"AB\"].fillna(\"\")\n",
    "\n",
    "# Create the column \"ClearlyHCM\" which is 1 if the title contains \"hypertrophic card*\", or \"HCM\", or \"HOCM\"\n",
    "df_all[\"HCM_In_Title\"] = df_all[\"TI\"].str.contains(\"hypertrophic card*|HCM|HOCM\", case=False, regex=True).astype(int)\n",
    "df_all[\"HCM_In_Abstract\"] = df_all[\"AB\"].str.contains(\"hypertrophic card*|HCM|HOCM\", case=False, regex=True).astype(int)\n",
    "\n",
    "\n",
    "# Create the column \"ECG_In_Title\" which is set to \"Yes\" if the title contains \"ECG\" or \"electrocardio*\", and \"No\" otherwise\n",
    "df_all[\"ECG_In_Title\"] = df_all[\"TI\"].apply(lambda x: \"ECG\" if \"ECG\" in x or \"electrocardio\" in x.lower() else \"Other\")\n",
    "df_all[\"ECG_In_Abstract\"] = df_all[\"AB\"].apply(lambda x: \"ECG\" if \"ECG\" in x or \"electrocardio\" in x.lower() else \"Other\")\n",
    "\n",
    "\n",
    "# Reorder columns in this order: PMID, HCM_In_Title, HCM_In_Abstract, ECG_In_Title, ECG_In_Abstract, TI, AB, and all others\n",
    "df_all = df_all[[\"PMID\", \"HCM_In_Title\", \"HCM_In_Abstract\", \"ECG_In_Title\", \"ECG_In_Abstract\", \"TI\", \"AB\"]]\n",
    "\n",
    "# Sort df_all by HCM_In_Title in descending order, then by HCM_In_Abstract in descending order, then by ECG_In_Title in descending order, and then by ECG_In_Abstract in descending order\n",
    "df_all = df_all.sort_values(by=[\"HCM_In_Title\", \"HCM_In_Abstract\", \"ECG_In_Title\", \"ECG_In_Abstract\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in columns HCM_In_Title, HCM_In_Abstract replace 1 with \"Yes\" and 0 with \"No\"\n",
    "df_all[\"HCM_In_Title\"] = df_all[\"HCM_In_Title\"].replace({1: \"Yes\", 0: \"No\"})\n",
    "df_all[\"HCM_In_Abstract\"] = df_all[\"HCM_In_Abstract\"].replace({1: \"Yes\", 0: \"No\"})\n",
    "\n",
    "# in columns ECG_In_Title, ECG_In_Abstract replace \"ECG\" with \"Yes\" and \"Other\" with \"No\"\n",
    "df_all[\"ECG_In_Title\"] = df_all[\"ECG_In_Title\"].replace({\"ECG\": \"Yes\", \"Other\": \"No\"})\n",
    "df_all[\"ECG_In_Abstract\"] = df_all[\"ECG_In_Abstract\"].replace({\"ECG\": \"Yes\", \"Other\": \"No\"})\n",
    "\n",
    "df_all.to_csv(\"df_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
